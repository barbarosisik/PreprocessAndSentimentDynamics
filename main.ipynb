{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jk1M5uWM1vVE",
    "outputId": "733abf43-1703-44dd-9998-2d06a95ab043"
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install emoji\n",
    "!pip install re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ws3fukUf1qMk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uA_5TKO20vp"
   },
   "outputs": [],
   "source": [
    "# Sample code to load and merge datasets - replace with actual dataset loading code\n",
    "def load_and_merge_datasets(file_paths):\n",
    "    merged_data = pd.DataFrame(columns=['TweetID', 'Sentiment', 'Tweet'])\n",
    "    for file_path in file_paths:\n",
    "        data = pd.read_csv(file_path, sep='\\t', header=None, names=['TweetID', 'Sentiment', 'Tweet'])\n",
    "        merged_data = pd.concat([merged_data, data], ignore_index=True)\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HaXHiTMF257d"
   },
   "outputs": [],
   "source": [
    "# Paths to your datasets\n",
    "train_files = ['twitter-2013train-A.tsv', 'twitter-2015train-A.tsv', 'twitter-2016train-A.tsv']\n",
    "test_files = ['twitter-2013test-A.tsv', 'twitter-2014test-A.tsv', 'twitter-2015test-A.tsv', 'twitter-2016test-A.tsv']\n",
    "dev_files = ['twitter-2013dev-A.tsv', 'twitter-2016dev-A.tsv', 'twitter-2016devtest-A.tsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "Px9KpP7L27lY",
    "outputId": "a53bd291-26a7-4cc6-eae2-1739ced7f9a5"
   },
   "outputs": [],
   "source": [
    "# Load and merge datasets\n",
    "train_data = load_and_merge_datasets(train_files)\n",
    "test_data = load_and_merge_datasets(test_files)\n",
    "dev_data = load_and_merge_datasets(dev_files)\n",
    "combined_data = pd.concat([train_data, test_data, dev_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qABgRuWN3T8r"
   },
   "outputs": [],
   "source": [
    "print(combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95gSnKdak8Wf"
   },
   "source": [
    "## Visualization of the Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMxryL28iw3M"
   },
   "outputs": [],
   "source": [
    "# Ensure that the 'Sentiment' column is treated as a string and strip any whitespace\n",
    "combined_data['Sentiment'] = combined_data['Sentiment'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXIjuk6VCau2"
   },
   "outputs": [],
   "source": [
    "# Map sentiment labels to a consistent format if they're not already\n",
    "sentiment_mapping = {'positive': 'positive', 'negative': 'negative', 'neutral': 'neutral'}\n",
    "combined_data['Sentiment'] = combined_data['Sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-GMwJTZB4H-"
   },
   "source": [
    "Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lyosc_YD6T2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy2uLj68HxJO"
   },
   "outputs": [],
   "source": [
    "positive_tweets = preprocess_data(data=train_data_non_nan, use_stemming=True, use_lemmatization=True, remove_emojis=True,\n",
    "                    remove_urls_and_html_tags=True, remove_punctuation_and_special_chars=True,\n",
    "                    remove_stopwords=True)[preprocess_data(data=train_data_non_nan, use_stemming=True,\n",
    "                                                           use_lemmatization=True,\n",
    "                                                           remove_emojis=True,\n",
    "                                                           remove_urls_and_html_tags=True,\n",
    "                                                           remove_punctuation_and_special_chars=True,\n",
    "                                                           remove_stopwords=True)[\n",
    "                                               'Sentiment'] == 'positive']['Tweet']\n",
    "negative_tweets = preprocess_data(data=train_data_non_nan, use_stemming=True, use_lemmatization=True, remove_emojis=True,\n",
    "                    remove_urls_and_html_tags=True, remove_punctuation_and_special_chars=True,\n",
    "                    remove_stopwords=True)[preprocess_data(data=train_data_non_nan, use_stemming=True,\n",
    "                                                           use_lemmatization=True,\n",
    "                                                           remove_emojis=True,\n",
    "                                                           remove_urls_and_html_tags=True,\n",
    "                                                           remove_punctuation_and_special_chars=True,\n",
    "                                                           remove_stopwords=True)\n",
    "                                           ['Sentiment'] == 'negative']['Tweet']\n",
    "neutral_tweets = preprocess_data(data=train_data_non_nan, use_stemming=True, use_lemmatization=True, remove_emojis=True,\n",
    "                                 remove_urls_and_html_tags=True, remove_punctuation_and_special_chars=True,\n",
    "                                 remove_stopwords=True)[preprocess_data(data=train_data_non_nan, use_stemming=True,\n",
    "                                                                        use_lemmatization=True,\n",
    "                                                                        remove_emojis=True,\n",
    "                                                                        remove_urls_and_html_tags=True,\n",
    "                                                                        remove_punctuation_and_special_chars=True,\n",
    "                                                                        remove_stopwords=True)\n",
    "                                                        ['Sentiment'] == 'neutral'][\"Tweet\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exyBrN21Dl4R"
   },
   "outputs": [],
   "source": [
    "# Generate Word Clouds\n",
    "def generate_word_cloud(tweets, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    wc = WordCloud(background_color='white', max_words=500, width=800, height=400, collocations=False).generate(\" \".join(tweets.astype(str)))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Fu30vy9EMeG"
   },
   "outputs": [],
   "source": [
    "generate_word_cloud(positive_tweets, 'Word Cloud for Positive Tweets')\n",
    "generate_word_cloud(negative_tweets, 'Word Cloud for Negative Tweets')\n",
    "generate_word_cloud(neutral_tweets, 'Word Cloud for Neutral Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou27e8tucQkn"
   },
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKet0zvgdY5r"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rK9BJ8vNcznV"
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "combined_data = combined_data.dropna(subset=['Tweet', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-1yzgOJdG8i"
   },
   "outputs": [],
   "source": [
    "# Split the combined dataset into features (tweets) and labels (sentiments)\n",
    "X = combined_data['Tweet']\n",
    "y = combined_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKDEbjC2dJmr"
   },
   "outputs": [],
   "source": [
    "# Vectorize the features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU6_xe80dKDL"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAf1XBjHdOPy"
   },
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression(class_weight='balanced',C=0.8,max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxPSJulTdQZF"
   },
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSVPexZ_dR_F"
   },
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xSinsO5dbTE"
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(sentiment_mapping.keys())\n",
    "ax.yaxis.set_ticklabels(sentiment_mapping.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7jnyjBjIEf2"
   },
   "source": [
    "Line Chart for Evaluation of the Sentiment Distribution for Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayC6sBmXILgf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puP6jeWlIOsF"
   },
   "outputs": [],
   "source": [
    "# File paths for the datasets of each year\n",
    "file_paths = {\n",
    "    '2013': ['twitter-2013train-A.tsv', 'twitter-2013dev-A.tsv', 'twitter-2013test-A.tsv'],\n",
    "    '2014': ['twitter-2014sarcasm-A.tsv', 'twitter-2014test-A.tsv'],\n",
    "    '2015': ['twitter-2015test-A.tsv', 'twitter-2015train-A.tsv'],\n",
    "    '2016': ['twitter-2016dev-A.tsv', 'twitter-2016devtest-A.tsv', 'twitter-2016test-A.tsv', 'twitter-2016train-A.tsv']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElgxqAVJITYq"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold sentiment counts\n",
    "sentiment_counts_by_year = {year: {'positive': 0, 'negative': 0, 'neutral': 0} for year in file_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9-Vu9-xIydK"
   },
   "outputs": [],
   "source": [
    "# Load the datasets and count sentiments for each year\n",
    "for year, paths in file_paths.items():\n",
    "    for path in paths:\n",
    "        # Read the dataset\n",
    "        data = pd.read_csv(f'{path}', sep='\\t', header=None, names=['TweetID', 'Sentiment', 'Tweet'])\n",
    "\n",
    "        # Drop rows with NaN values\n",
    "        data = data.dropna(subset=['Tweet', 'Sentiment'])\n",
    "\n",
    "        # Count the sentiments\n",
    "        sentiment_counts = data['Sentiment'].value_counts()\n",
    "\n",
    "        # Update the sentiment counts for the year\n",
    "        for sentiment in ['positive', 'negative', 'neutral']:\n",
    "            if sentiment in sentiment_counts:\n",
    "                sentiment_counts_by_year[year][sentiment] += sentiment_counts[sentiment]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMdHUwbHI0jB"
   },
   "outputs": [],
   "source": [
    "# Prepare the data for the plot\n",
    "years = sorted(sentiment_counts_by_year.keys())\n",
    "positives = [sentiment_counts_by_year[year]['positive'] for year in years]\n",
    "negatives = [sentiment_counts_by_year[year]['negative'] for year in years]\n",
    "neutrals = [sentiment_counts_by_year[year]['neutral'] for year in years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmOMtC2OI2Rj"
   },
   "outputs": [],
   "source": [
    "# Create the line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(years, positives, 'g-o', label='Positive')  # Green line with dots for positives\n",
    "plt.plot(years, negatives, 'r-o', label='Negative')  # Red line with dots for negatives\n",
    "plt.plot(years, neutrals, 'b-o', label='Neutral')  # Blue line with dots for neutrals\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpodte-7cWT2"
   },
   "source": [
    "**Distribution of Sentiments (Bar Plot)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3oF8CGbiVUn"
   },
   "outputs": [],
   "source": [
    "# Calculate the sentiment counts\n",
    "sentiment_counts = combined_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bvat63eNCcfg"
   },
   "outputs": [],
   "source": [
    "# Plot the sentiment distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n",
    "plt.title('Sentiment Distribution in the Combined Dataset')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhe2Q67clHdn"
   },
   "outputs": [],
   "source": [
    "# Map sentiments to numerical values\n",
    "sentiment_mapping = {'neutral': 0, 'negative': 1, 'positive': 2}\n",
    "train_data['Sentiment'] = train_data['Sentiment'].map(sentiment_mapping)\n",
    "test_data['Sentiment'] = test_data['Sentiment'].map(sentiment_mapping)\n",
    "dev_data['Sentiment'] = dev_data['Sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxVYmBTRBusw"
   },
   "source": [
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-_QNZm3lLHB"
   },
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_data['Tweet'].fillna(''))  # Fill NaN with empty strings\n",
    "y_train = train_data['Sentiment']\n",
    "X_test = vectorizer.transform(test_data['Tweet'].fillna(''))  # Also fill NaN with empty strings in the test set\n",
    "y_test = test_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sFgCzWImpQ8"
   },
   "outputs": [],
   "source": [
    "# Training a Logistic Regression model as a baseline\n",
    "model = LogisticRegression(class_weight='balanced',C=0.8 ,max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUQW6R82n3YG"
   },
   "source": [
    "Removing the NaN value rows, because not allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rrg1J4g5n2va"
   },
   "outputs": [],
   "source": [
    "# Find rows where y_test_no_stop is not NaN\n",
    "valid_indices = y_test.notna()\n",
    "\n",
    "# Filter both X_test_no_stop and y_test_no_stop to remove NaNs\n",
    "X_test_filtered = X_test[valid_indices]\n",
    "y_test_filtered = y_test[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Uw5vZStFtCL"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "y_pred = model.predict(X_test_filtered)\n",
    "report = classification_report(y_test_filtered, y_pred, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro = precision_score(y_test_filtered, y_pred, average='macro')\n",
    "recall_macro = recall_score(y_test_filtered, y_pred, average='macro')\n",
    "f1_macro = f1_score(y_test_filtered, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test_filtered, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr8CwCePF06s"
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report for Baseline Model:\\n\", report)\n",
    "print(\"Macro-average Precision:\", precision_macro)\n",
    "print(\"Macro-average Recall:\", recall_macro)\n",
    "print(\"Macro-average F1-score:\", f1_macro)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uet1VzD1qtKQ"
   },
   "source": [
    "# Implementing Preprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3OwNtZ5FJPT"
   },
   "source": [
    "# Removing Punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxwtRdM_FOt2"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation_and_special_characters(text):\n",
    "    # Remove punctuation and special characters\n",
    "    text_without_punctuations = ''.join(char for char in text if char not in string.punctuation)\n",
    "\n",
    "    return text_without_punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afaat1L5EClC"
   },
   "source": [
    "# Removing URLs and HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40lhqya1EJJe"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQ3wizfXEBSf"
   },
   "outputs": [],
   "source": [
    "def remove_urls_and_html(text):\n",
    "    # Remove URLs\n",
    "    text_without_urls = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text_without_html = re.sub('<.*?>', '', text_without_urls)\n",
    "\n",
    "    return text_without_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUsMR-0Jq0Uf"
   },
   "source": [
    "# Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU-1qaDatwpk"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6GmjnuYt1tY"
   },
   "outputs": [],
   "source": [
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_and_lemmatize_text(text):\n",
    "    # First apply stemming\n",
    "    stemmed_text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    # Then apply lemmatization\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in stemmed_text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2kEgBcwvWOb"
   },
   "outputs": [],
   "source": [
    "# To not to change the raw dataset to use as it is on the next pre-processing methods,\n",
    "# we wanted to create a temporary datasets that lemmatized and stemmed\n",
    "train_data_stem_lem = train_data.copy()\n",
    "train_data_stem_lem['Tweet'] = train_data_stem_lem['Tweet'].apply(stem_and_lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP-19cd2zzrg"
   },
   "outputs": [],
   "source": [
    "# Fill NaN values with empty strings in both datasets\n",
    "train_data_stem_lem['Tweet'] = train_data_stem_lem['Tweet'].fillna('')\n",
    "test_data['Tweet'] = test_data['Tweet'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jky24IPQyMqL"
   },
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "vectorizer_stem_lem = TfidfVectorizer(max_features=5000)\n",
    "X_train_stem_lem = vectorizer_stem_lem.fit_transform(train_data_stem_lem['Tweet'])\n",
    "y_train_stem_lem = train_data_stem_lem['Sentiment']\n",
    "X_test_stem_lem = vectorizer_stem_lem.transform(test_data['Tweet'])  # Assuming test_data is already preprocessed\n",
    "y_test_stem_lem = test_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZbb7qk8yibE"
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model_stem_lem = LogisticRegression(class_weight='balanced',C=0.8,max_iter=1000)\n",
    "model_stem_lem.fit(X_train_stem_lem, y_train_stem_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTf1NUEe5oxl"
   },
   "outputs": [],
   "source": [
    "# Filtering out rows with NaN values in y_test_stem_lem\n",
    "valid_indices = y_test_stem_lem.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZT1M6XI0lr0"
   },
   "outputs": [],
   "source": [
    "# Ensuring that X_test_stem_lem and y_test_stem_lem have the same rows\n",
    "X_test_stem_lem_filtered = X_test_stem_lem[valid_indices]\n",
    "y_test_stem_lem_filtered = y_test_stem_lem[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14UU1RqVj98O"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_stem_lem = model_stem_lem.predict(X_test_stem_lem_filtered)\n",
    "report_stem_lem = classification_report(y_test_stem_lem_filtered, y_pred_stem_lem, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_stem_lem = precision_score(y_test_stem_lem_filtered, y_pred_stem_lem, average='macro')\n",
    "recall_macro_stem_lem = recall_score(y_test_stem_lem_filtered, y_pred_stem_lem, average='macro')\n",
    "f1_macro_stem_lem = f1_score(y_test_stem_lem_filtered, y_pred_stem_lem, average='macro')\n",
    "accuracy_stem_lem = accuracy_score(y_test_stem_lem_filtered, y_pred_stem_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BhlFpdRzDHo"
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report for Model with Stemming and Lematization:\\n\", report_stem_lem)\n",
    "print(\"macro-average Precision:\", precision_macro_stem_lem)\n",
    "print(\"macro-average Recall:\", recall_macro_stem_lem)\n",
    "print(\"macro-average F1-score:\", f1_macro_stem_lem)\n",
    "print(\"Accuracy:\", accuracy_stem_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKJOjPwp0-Th"
   },
   "source": [
    "As we can tell, stemming and lemmatization for a dataset like this, decreases the results taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vfujfLN1cTl"
   },
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPmVNmwt4guV"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2kD5xXY26gO"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEHZEvcY4kd-"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0NbCeYF4o6V"
   },
   "outputs": [],
   "source": [
    "# Create new temporary datasets with stop words removed\n",
    "train_data_no_stop = train_data.copy()\n",
    "train_data_no_stop['Tweet'] = train_data_no_stop['Tweet'].apply(remove_stopwords)\n",
    "\n",
    "test_data_no_stop = test_data.copy()\n",
    "test_data_no_stop['Tweet'] = test_data_no_stop['Tweet'].apply(remove_stopwords)\n",
    "\n",
    "dev_data_no_stop = dev_data.copy()\n",
    "dev_data_no_stop['Tweet'] = dev_data_no_stop['Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSHeFX674zkM"
   },
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "vectorizer_no_stop = TfidfVectorizer(max_features=5000)\n",
    "X_train_no_stop = vectorizer_no_stop.fit_transform(train_data_no_stop['Tweet'])\n",
    "y_train_no_stop = train_data_no_stop['Sentiment']\n",
    "X_test_no_stop = vectorizer_no_stop.transform(test_data_no_stop['Tweet'])\n",
    "y_test_no_stop = test_data_no_stop['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExsSTOpv41Mo"
   },
   "outputs": [],
   "source": [
    "# Training the Logistic Regression model\n",
    "model_no_stop = LogisticRegression(class_weight='balanced',C=0.8,max_iter=1000)\n",
    "model_no_stop.fit(X_train_no_stop, y_train_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UC2VsJiP7TUh"
   },
   "outputs": [],
   "source": [
    "# Find rows where y_test_no_stop is not NaN\n",
    "valid_indices = y_test_no_stop.notna()\n",
    "\n",
    "# Filter both X_test_no_stop and y_test_no_stop to remove NaNs\n",
    "X_test_no_stop_filtered = X_test_no_stop[valid_indices]\n",
    "y_test_no_stop_filtered = y_test_no_stop[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MJSZgZ56r9n"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_no_stop = model_no_stop.predict(X_test_no_stop_filtered)\n",
    "report_no_stop = classification_report(y_test_no_stop_filtered, y_pred_no_stop, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_no_stop = precision_score(y_test_no_stop_filtered, y_pred_no_stop, average='macro')\n",
    "recall_macro_no_stop = recall_score(y_test_no_stop_filtered, y_pred_no_stop, average='macro')\n",
    "f1_macro_no_stop = f1_score(y_test_no_stop_filtered, y_pred_no_stop, average='macro')\n",
    "accuracy_no_stop = accuracy_score(y_test_no_stop_filtered, y_pred_no_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOkDptb0jgvf"
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report for Model with Stop Words Removed:\\n\", report_no_stop)\n",
    "print(\"macro-average Precision:\", precision_macro_no_stop)\n",
    "print(\"macro-average Recall:\", recall_macro_no_stop)\n",
    "print(\"macro-average F1-score:\", f1_macro_no_stop)\n",
    "print(\"Accuracy:\", accuracy_no_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puDxXCaeblMk"
   },
   "source": [
    "# Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hh68DbZzboNU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9NihtRken7q"
   },
   "outputs": [],
   "source": [
    "# Copying the raw datasets\n",
    "train_data = train_data.copy()\n",
    "test_data = test_data.copy()\n",
    "dev_data = dev_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYfdViQcevFI"
   },
   "outputs": [],
   "source": [
    "# Applying lowercasing to the copied datasets\n",
    "train_data_lower = train_data.copy()\n",
    "train_data_lower['Tweet'] = train_data_lower['Tweet'].str.lower()\n",
    "\n",
    "test_data_lower = test_data.copy()\n",
    "test_data_lower['Tweet'] = test_data_lower['Tweet'].str.lower()\n",
    "\n",
    "dev_data_lower = dev_data.copy()\n",
    "dev_data_lower['Tweet'] = dev_data_lower['Tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzWbhst4dXH5"
   },
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "vectorizer_lower = TfidfVectorizer(max_features=5000)\n",
    "X_train_lower = vectorizer_lower.fit_transform(train_data_lower['Tweet'])\n",
    "y_train_lower = train_data_lower['Sentiment']\n",
    "X_test_lower = vectorizer_lower.transform(test_data_lower['Tweet'])\n",
    "y_test_lower = test_data_lower['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pvqHx04dZZx"
   },
   "outputs": [],
   "source": [
    "# Training the SVM model (others were with Logistic Regression)\n",
    "model_lower = SVC(kernel='linear')  # Using a linear kernel\n",
    "model_lower.fit(X_train_lower, y_train_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FJtowNHhIkn"
   },
   "outputs": [],
   "source": [
    "# Find rows where y_test_no_stop is not NaN\n",
    "valid_indices = y_test_lower.notna()\n",
    "\n",
    "# Filter both X_test_no_stop and y_test_no_stop to remove NaNs\n",
    "X_test_lower_filtered = X_test_lower[valid_indices]\n",
    "y_test_lower_filtered = y_test_lower[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAe3LjmudeWM"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_lower = model_lower.predict(X_test_lower_filtered)\n",
    "report_lower = classification_report(y_test_lower_filtered, y_pred_lower, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_lower = precision_score(y_test_lower_filtered, y_pred_lower, average='macro')\n",
    "recall_macro_lower = recall_score(y_test_lower_filtered, y_pred_lower, average='macro')\n",
    "f1_macro_lower = f1_score(y_test_lower_filtered, y_pred_lower, average='macro')\n",
    "accuracy_lower = accuracy_score(y_test_lower_filtered, y_pred_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFn11fogdfIs"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Classification Report for Lowercased Model:\\n\", report_lower)\n",
    "print(\"macro-average Precision:\", precision_macro_lower)\n",
    "print(\"macro-average Recall:\", recall_macro_lower)\n",
    "print(\"macro-average F1-score:\", f1_macro_lower)\n",
    "print(\"Accuracy:\", accuracy_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQcSTfF0DJMn"
   },
   "source": [
    "**Training The Model with Baseline (Logistic Regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bmL-4mrRN60"
   },
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "vectorizer_lower = TfidfVectorizer(max_features=5000)\n",
    "X_train_lower = vectorizer_lower.fit_transform(train_data_lower['Tweet'])\n",
    "y_train_lower = train_data_lower['Sentiment']\n",
    "X_test_lower = vectorizer_lower.transform(test_data_lower['Tweet'])\n",
    "y_test_lower = test_data_lower['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uB-HnmfYKBUK"
   },
   "outputs": [],
   "source": [
    "# Training the Logistic Regression model\n",
    "model_lower_lr = LogisticRegression(class_weight='balanced',C=0.8,max_iter=1000)\n",
    "model_lower_lr.fit(X_train_lower, y_train_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FU4UDmPvQ6fG"
   },
   "outputs": [],
   "source": [
    "# Filter out NaN values and align X and y\n",
    "valid_indices = y_test_lower.notna()\n",
    "X_test_lower_filtered = X_test_lower[valid_indices]\n",
    "y_test_lower_filtered = y_test_lower[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82mr3qI7PJbE"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_lower_lr = model_lower_lr.predict(X_test_lower_filtered)\n",
    "report_lower_lr = classification_report(y_test_lower_filtered, y_pred_lower_lr, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_lower_lr = precision_score(y_test_lower_filtered, y_pred_lower_lr, average='macro')\n",
    "recall_macro_lower_lr = recall_score(y_test_lower_filtered, y_pred_lower_lr, average='macro')\n",
    "f1_macro_lower_lr = f1_score(y_test_lower_filtered, y_pred_lower_lr, average='macro')\n",
    "accuracy_lower_lr = accuracy_score(y_test_lower_filtered, y_pred_lower_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uo66Qjn9PN_8"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Classification Report for Lowercased Model with Logistic Regression:\\n\", report_lower_lr)\n",
    "print(\"Macro-average Precision:\", precision_macro_lower_lr)\n",
    "print(\"Macro-average Recall:\", recall_macro_lower_lr)\n",
    "print(\"Macro-average F1-score:\", f1_macro_lower_lr)\n",
    "print(\"Accuracy:\", accuracy_lower_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFmVrDPTlT7I"
   },
   "source": [
    "# Removing Punctuation and Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpHVCuj4qtVI"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keiC7WbKqwpU"
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMKsySVPlWum"
   },
   "outputs": [],
   "source": [
    "# Copying the raw datasets\n",
    "train_data = train_data.copy()\n",
    "test_data = test_data.copy()\n",
    "dev_data = dev_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZ4hpGHUqyDV"
   },
   "outputs": [],
   "source": [
    "# Apply the function to remove punctuation and special characters\n",
    "train_data_no_punct = train_data.copy()\n",
    "train_data_no_punct['Tweet'] = train_data_no_punct['Tweet'].apply(remove_punctuation)\n",
    "\n",
    "test_data_no_punct = test_data.copy()\n",
    "test_data_no_punct['Tweet'] = test_data_no_punct['Tweet'].apply(remove_punctuation)\n",
    "\n",
    "dev_data_no_punct = dev_data.copy()\n",
    "dev_data_no_punct['Tweet'] = dev_data_no_punct['Tweet'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdLl1NFhrbKl"
   },
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "vectorizer_no_punct = TfidfVectorizer(max_features=5000)\n",
    "X_train_no_punct = vectorizer_no_punct.fit_transform(train_data_no_punct['Tweet'])\n",
    "y_train_no_punct = train_data_no_punct['Sentiment']\n",
    "X_test_no_punct = vectorizer_no_punct.transform(test_data_no_punct['Tweet'])\n",
    "y_test_no_punct = test_data_no_punct['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_WQofjOreKs"
   },
   "outputs": [],
   "source": [
    "# Training the Random Forest model\n",
    "model_no_punct = RandomForestClassifier()\n",
    "model_no_punct.fit(X_train_no_punct, y_train_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLNxqqLCtm-2"
   },
   "outputs": [],
   "source": [
    "# Find rows where y_test_no_stop is not NaN\n",
    "valid_indices = y_test_no_punct.notna()\n",
    "\n",
    "# Filter both X_test_no_stop and y_test_no_stop to remove NaNs\n",
    "X_test_no_punct_filtered = X_test_no_punct[valid_indices]\n",
    "y_test_no_punct_filtered = y_test_no_punct[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecLZWHkEsFnk"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_no_punct = model_no_punct.predict(X_test_no_punct_filtered)\n",
    "report_no_punct = classification_report(y_test_no_punct_filtered, y_pred_no_punct, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_no_punct = precision_score(y_test_no_punct_filtered, y_pred_no_punct, average='macro')\n",
    "recall_macro_no_punct = recall_score(y_test_no_punct_filtered, y_pred_no_punct, average='macro')\n",
    "f1_macro_no_punct = f1_score(y_test_no_punct_filtered, y_pred_no_punct, average='macro')\n",
    "accuracy_no_punct = accuracy_score(y_test_no_punct_filtered, y_pred_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6Axko6WuEmK"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Classification Report for Punctuation Model:\\n\", report_no_punct)\n",
    "print(\"macro-average Precision:\", precision_macro_no_punct)\n",
    "print(\"macro-average Recall:\", recall_macro_no_punct)\n",
    "print(\"macro-average F1-score:\", f1_macro_no_punct)\n",
    "print(\"Accuracy:\", accuracy_no_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkdmT65NDZpu"
   },
   "source": [
    "**Training The Model with Baseline (Logistic Regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNQaqnLTD4Pw"
   },
   "outputs": [],
   "source": [
    "# Training the Logistic Regression model\n",
    "model_no_punct_lr = LogisticRegression(class_weight='balanced',C=0.8,max_iter=1000)\n",
    "model_no_punct_lr.fit(X_train_no_punct, y_train_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9jsRLl8UKae"
   },
   "outputs": [],
   "source": [
    "# Filter out rows where y_test_no_punct is NaN\n",
    "valid_indices = y_test_no_punct.notna()\n",
    "X_test_no_punct_filtered = X_test_no_punct[valid_indices]\n",
    "y_test_no_punct_filtered = y_test_no_punct[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgLRNi0rToGX"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model with the filtered data\n",
    "y_pred_no_punct_lr = model_no_punct_lr.predict(X_test_no_punct_filtered)\n",
    "report_no_punct_lr = classification_report(y_test_no_punct_filtered, y_pred_no_punct_lr, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_no_punct_lr = precision_score(y_test_no_punct_filtered, y_pred_no_punct_lr, average='macro')\n",
    "recall_macro_no_punct_lr = recall_score(y_test_no_punct_filtered, y_pred_no_punct_lr, average='macro')\n",
    "f1_macro_no_punct_lr = f1_score(y_test_no_punct_filtered, y_pred_no_punct_lr, average='macro')\n",
    "accuracy_no_punct_lr = accuracy_score(y_test_no_punct_filtered, y_pred_no_punct_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGqiXOBiTosN"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Classification Report for Logistic Regression Model with Punctuation and Special Characters Removed:\\n\", report_no_punct_lr)\n",
    "print(\"Macro-average Precision:\", precision_macro_no_punct_lr)\n",
    "print(\"Macro-average Recall:\", recall_macro_no_punct_lr)\n",
    "print(\"Macro-average F1-score:\", f1_macro_no_punct_lr)\n",
    "print(\"Accuracy:\", accuracy_no_punct_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ior45aWalXoI"
   },
   "source": [
    "# Removing URLs and HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xjtHIE3la_6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qL1WKo3wwDvt"
   },
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWdVqnRYwzMi"
   },
   "outputs": [],
   "source": [
    "# Copying the raw datasets\n",
    "train_data_no_url_html = train_data.copy()\n",
    "train_data_no_url_html['Tweet'] = train_data_no_url_html['Tweet'].apply(remove_urls).apply(remove_html_tags)\n",
    "\n",
    "test_data_no_url_html = test_data.copy()\n",
    "test_data_no_url_html['Tweet'] = test_data_no_url_html['Tweet'].apply(remove_urls).apply(remove_html_tags)\n",
    "\n",
    "dev_data_no_url_html = dev_data.copy()\n",
    "dev_data_no_url_html['Tweet'] = dev_data_no_url_html['Tweet'].apply(remove_urls).apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QH75O1VzxmZm"
   },
   "outputs": [],
   "source": [
    "# Filter out NaN values\n",
    "train_data_no_url_html = train_data_no_url_html.dropna()\n",
    "test_data_no_url_html = test_data_no_url_html.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fj5-sDkKyKLg"
   },
   "outputs": [],
   "source": [
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data_no_url_html['Tweet'])\n",
    "\n",
    "X_train_nn = tokenizer.texts_to_sequences(train_data_no_url_html['Tweet'])\n",
    "X_train_nn = pad_sequences(X_train_nn, maxlen=100)\n",
    "\n",
    "X_test_nn = tokenizer.texts_to_sequences(test_data_no_url_html['Tweet'])\n",
    "X_test_nn = pad_sequences(X_test_nn, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqEk0fUvyPWy"
   },
   "outputs": [],
   "source": [
    "# Convert labels to categorical\n",
    "y_train_nn = to_categorical(np.array(train_data_no_url_html['Sentiment']))\n",
    "y_test_nn = to_categorical(np.array(test_data_no_url_html['Sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgBXnUgmySLX"
   },
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Embedding(input_dim=5000, output_dim=64, input_length=100))\n",
    "model_nn.add(GlobalAveragePooling1D())\n",
    "model_nn.add(Dense(3, activation='softmax'))  # Assuming 3 classes: Neutral, Negative, Positive\n",
    "\n",
    "model_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_nn.fit(X_train_nn, y_train_nn, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhMXeigWyVuH"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_nn = np.argmax(model_nn.predict(X_test_nn), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sc_gncY5yXTr"
   },
   "outputs": [],
   "source": [
    "# Convert y_test from categorical to single label\n",
    "y_test_single_label = np.argmax(y_test_nn, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FriYG3nvzaHl"
   },
   "outputs": [],
   "source": [
    "# Classification report and other metrics\n",
    "report_nn = classification_report(y_test_single_label, y_pred_nn, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_nn = precision_score(y_test_single_label, y_pred_nn, average='macro')\n",
    "recall_macro_nn = recall_score(y_test_single_label, y_pred_nn, average='macro')\n",
    "f1_macro_nn = f1_score(y_test_single_label, y_pred_nn, average='macro')\n",
    "accuracy_nn = accuracy_score(y_test_single_label, y_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZJEhftMzbt-"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Classification Report for Neural Network Model:\\n\", report_nn)\n",
    "print(\"macro-average Precision:\", precision_macro_nn)\n",
    "print(\"macro-average Recall:\", recall_macro_nn)\n",
    "print(\"macro-average F1-score:\", f1_macro_nn)\n",
    "print(\"Accuracy:\", accuracy_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgeG-iU_D6CL"
   },
   "source": [
    "Training The Model with Baseline (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_RYYzi6WGts"
   },
   "outputs": [],
   "source": [
    "# Filter out NaN values\n",
    "train_data_no_url_html = train_data_no_url_html.dropna()\n",
    "test_data_no_url_html = test_data_no_url_html.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGw7ToYOWJJV"
   },
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "vectorizer_no_url_html = TfidfVectorizer(max_features=5000)\n",
    "X_train_no_url_html = vectorizer_no_url_html.fit_transform(train_data_no_url_html['Tweet'])\n",
    "y_train_no_url_html = train_data_no_url_html['Sentiment']\n",
    "X_test_no_url_html = vectorizer_no_url_html.transform(test_data_no_url_html['Tweet'])\n",
    "y_test_no_url_html = test_data_no_url_html['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aulYCbidWJzc"
   },
   "outputs": [],
   "source": [
    "# Training the Logistic Regression model\n",
    "model_no_url_html_lr = LogisticRegression(class_weight='balanced', C=0.8, max_iter=1000)\n",
    "model_no_url_html_lr.fit(X_train_no_url_html, y_train_no_url_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiF5EGfNWSJj"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_no_url_html_lr = model_no_url_html_lr.predict(X_test_no_url_html)\n",
    "report_no_url_html_lr = classification_report(y_test_no_url_html, y_pred_no_url_html_lr, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_no_url_html_lr = precision_score(y_test_no_url_html, y_pred_no_url_html_lr, average='macro')\n",
    "recall_macro_no_url_html_lr = recall_score(y_test_no_url_html, y_pred_no_url_html_lr, average='macro')\n",
    "f1_macro_no_url_html_lr = f1_score(y_test_no_url_html, y_pred_no_url_html_lr, average='macro')\n",
    "accuracy_no_url_html_lr = accuracy_score(y_test_no_url_html, y_pred_no_url_html_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcrN2W6YWTrW"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Classification Report for Logistic Regression Model with URLs and HTML Tags Removed:\\n\", report_no_url_html_lr)\n",
    "print(\"Macro-average Precision:\", precision_macro_no_url_html_lr)\n",
    "print(\"Macro-average Recall:\", recall_macro_no_url_html_lr)\n",
    "print(\"Macro-average F1-score:\", f1_macro_no_url_html_lr)\n",
    "print(\"Accuracy:\", accuracy_no_url_html_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnet6KqJ7N1y"
   },
   "source": [
    "# Removing Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T99WRP_Mlkt3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSkGJkxGBjAi"
   },
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzbDdsDIBOk3"
   },
   "outputs": [],
   "source": [
    "# Copying the raw datasets\n",
    "train_data_no_numbers = train_data.copy()\n",
    "train_data_no_numbers['Tweet'] = train_data_no_numbers['Tweet'].apply(remove_numbers)\n",
    "\n",
    "test_data_no_numbers = test_data.copy()\n",
    "test_data_no_numbers['Tweet'] = test_data_no_numbers['Tweet'].apply(remove_numbers)\n",
    "\n",
    "dev_data_no_numbers = dev_data.copy()\n",
    "dev_data_no_numbers['Tweet'] = dev_data_no_numbers['Tweet'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klY2IjofBQDV"
   },
   "outputs": [],
   "source": [
    "# Filter out NaN values\n",
    "train_data_no_numbers = train_data_no_numbers.dropna()\n",
    "test_data_no_numbers = test_data_no_numbers.dropna()\n",
    "dev_data_no_numbers = dev_data_no_numbers.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgmioHq0_4z9"
   },
   "outputs": [],
   "source": [
    "# Vectorization with TF-IDF\n",
    "vectorizer_no_numbers = TfidfVectorizer(max_features=5000)\n",
    "X_train_no_numbers = vectorizer_no_numbers.fit_transform(train_data_no_numbers['Tweet'])\n",
    "y_train_no_numbers = train_data_no_numbers['Sentiment']\n",
    "X_test_no_numbers = vectorizer_no_numbers.transform(test_data_no_numbers['Tweet'])\n",
    "y_test_no_numbers = test_data_no_numbers['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvGeM9-sABU-"
   },
   "outputs": [],
   "source": [
    "# Training the Logistic Regression model\n",
    "model_no_numbers = LogisticRegression(class_weight='balanced',C=0.8,max_iter=1000)\n",
    "model_no_numbers.fit(X_train_no_numbers, y_train_no_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RltqNh2qAEo2"
   },
   "outputs": [],
   "source": [
    "# Predicting and evaluating the model\n",
    "y_pred_no_numbers = model_no_numbers.predict(X_test_no_numbers)\n",
    "report_no_numbers = classification_report(y_test_no_numbers, y_pred_no_numbers, target_names=['Neutral', 'Negative', 'Positive'])\n",
    "precision_macro_no_numbers = precision_score(y_test_no_numbers, y_pred_no_numbers, average='macro')\n",
    "recall_macro_no_numbers = recall_score(y_test_no_numbers, y_pred_no_numbers, average='macro')\n",
    "f1_macro_no_numbers = f1_score(y_test_no_numbers, y_pred_no_numbers, average='macro')\n",
    "accuracy_no_numbers = accuracy_score(y_test_no_numbers, y_pred_no_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZLRpJJ8AHKK"
   },
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Classification Report for Logistic Regression Model with Numbers Removed:\\n\", report_no_numbers)\n",
    "print(\"macro-average Precision:\", precision_macro_no_numbers)\n",
    "print(\"macro-average Recall:\", recall_macro_no_numbers)\n",
    "print(\"macro-average F1-score:\", f1_macro_no_numbers)\n",
    "print(\"Accuracy:\", accuracy_no_numbers)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
